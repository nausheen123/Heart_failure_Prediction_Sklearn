{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-13T21:02:35.664292Z","iopub.execute_input":"2021-11-13T21:02:35.664651Z","iopub.status.idle":"2021-11-13T21:02:35.695530Z","shell.execute_reply.started":"2021-11-13T21:02:35.664564Z","shell.execute_reply":"2021-11-13T21:02:35.694728Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"The project is about predicting heart failure from existing data. ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport seaborn as sb\n","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:35.697409Z","iopub.execute_input":"2021-11-13T21:02:35.697804Z","iopub.status.idle":"2021-11-13T21:02:36.540492Z","shell.execute_reply.started":"2021-11-13T21:02:35.697770Z","shell.execute_reply":"2021-11-13T21:02:36.539650Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:36.541603Z","iopub.execute_input":"2021-11-13T21:02:36.541825Z","iopub.status.idle":"2021-11-13T21:02:36.558408Z","shell.execute_reply.started":"2021-11-13T21:02:36.541798Z","shell.execute_reply":"2021-11-13T21:02:36.557772Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:36.561134Z","iopub.execute_input":"2021-11-13T21:02:36.561803Z","iopub.status.idle":"2021-11-13T21:02:36.584148Z","shell.execute_reply.started":"2021-11-13T21:02:36.561770Z","shell.execute_reply":"2021-11-13T21:02:36.583420Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:36.585202Z","iopub.execute_input":"2021-11-13T21:02:36.585954Z","iopub.status.idle":"2021-11-13T21:02:36.607850Z","shell.execute_reply.started":"2021-11-13T21:02:36.585920Z","shell.execute_reply":"2021-11-13T21:02:36.606996Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#check for null values and duplicates\ndata.isnull().any()\ndata.duplicated().any()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:36.609118Z","iopub.execute_input":"2021-11-13T21:02:36.609364Z","iopub.status.idle":"2021-11-13T21:02:36.621505Z","shell.execute_reply.started":"2021-11-13T21:02:36.609335Z","shell.execute_reply":"2021-11-13T21:02:36.620511Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"To get a better idea of what type of data is in the columns we can use unique function with the columns ","metadata":{}},{"cell_type":"code","source":"print(\"Age rangees from:\", data['age'].unique())\nprint(\"sex values are:\",data['sex'].unique())\nprint(\"Age rangees from:\", data['age'].unique())","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:36.623076Z","iopub.execute_input":"2021-11-13T21:02:36.623951Z","iopub.status.idle":"2021-11-13T21:02:36.632856Z","shell.execute_reply.started":"2021-11-13T21:02:36.623900Z","shell.execute_reply":"2021-11-13T21:02:36.632031Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"column_list = data.columns.values.tolist()\nfor column_name in column_list:\n    print(column_name,data[column_name].unique())","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:36.634380Z","iopub.execute_input":"2021-11-13T21:02:36.634901Z","iopub.status.idle":"2021-11-13T21:02:36.654606Z","shell.execute_reply.started":"2021-11-13T21:02:36.634862Z","shell.execute_reply":"2021-11-13T21:02:36.653952Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"column_list","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:36.655663Z","iopub.execute_input":"2021-11-13T21:02:36.656414Z","iopub.status.idle":"2021-11-13T21:02:36.662089Z","shell.execute_reply.started":"2021-11-13T21:02:36.656380Z","shell.execute_reply":"2021-11-13T21:02:36.661288Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#visualize data\n#VISUALISATION\nf, x = plt.subplots(4, 2, figsize = (15, 10))\nsb.countplot(x = data[\"smoking\"], data = data, palette = 'mako', ax = x[0, 0])\nsb.countplot(x = data[\"anaemia\"], data = data, palette = 'crest', ax = x[0, 1])\nsb.countplot(x = data[\"ejection_fraction\"], data = data,palette = 'mako', ax = x[1, 0])\nsb.countplot(x = data[\"high_blood_pressure\"], data = data, palette = 'crest',ax = x[1, 1])\nsb.countplot(x = data[\"sex\"], data = data, palette = 'crest',ax = x[2, 0])\nsb.countplot(x = data[\"diabetes\"], data = data, palette = 'crest',ax = x[2, 1])\nsb.countplot(x = data[\"DEATH_EVENT\"], data = data, palette = 'crest',ax = x[3, 0])\nsb.countplot(x = data[\"diabetes\"], data = data, palette = 'crest',ax = x[3, 1])\n\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:36.664485Z","iopub.execute_input":"2021-11-13T21:02:36.665171Z","iopub.status.idle":"2021-11-13T21:02:37.734139Z","shell.execute_reply.started":"2021-11-13T21:02:36.665136Z","shell.execute_reply":"2021-11-13T21:02:37.733346Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# looking at the distributions \nsb.displot(x = data[\"platelets\"], data = data, color = 'c', kind = 'kde')\nsb.displot(x = data[\"age\"], data = data, color = 'c', kind = 'hist')\nsb.displot(x = data[\"serum_creatinine\"], data = data, color = 'c', kind = 'hist')","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:37.735439Z","iopub.execute_input":"2021-11-13T21:02:37.735646Z","iopub.status.idle":"2021-11-13T21:02:38.820878Z","shell.execute_reply.started":"2021-11-13T21:02:37.735620Z","shell.execute_reply":"2021-11-13T21:02:38.820118Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":" **We see that  there is no non-numerical values in these columns therefore we dont need to perform encoding for any categorical variables.**","metadata":{}},{"cell_type":"code","source":"#define the target prediction and the features\nX = data.iloc[:,0:11] #  # death is our target to show a heart failure\nY = data.iloc[:,12].values # features\n","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:38.822091Z","iopub.execute_input":"2021-11-13T21:02:38.822552Z","iopub.status.idle":"2021-11-13T21:02:38.827044Z","shell.execute_reply.started":"2021-11-13T21:02:38.822522Z","shell.execute_reply":"2021-11-13T21:02:38.826339Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# split the data set into training and testing dataset with  80:20 ratio\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train,Y_test =train_test_split(X, Y, test_size=0.2,random_state=0)\n# random state is  used  for initializing the internal random number generator, which will decide the splitting of data into train and test indices\n","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:38.828287Z","iopub.execute_input":"2021-11-13T21:02:38.828518Z","iopub.status.idle":"2021-11-13T21:02:39.005722Z","shell.execute_reply.started":"2021-11-13T21:02:38.828491Z","shell.execute_reply":"2021-11-13T21:02:39.004820Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":" Gradient Boosting model\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.metrics import accuracy_score\n\ngb_model = GradientBoostingClassifier(n_estimators=600, learning_rate= .01, random_state=0)\ngb_model.fit(X_train, Y_train)\ngb_preds = gb_model.predict(X_test)\naccuracy = accuracy_score(Y_test, gb_preds)\n\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:39.007313Z","iopub.execute_input":"2021-11-13T21:02:39.007939Z","iopub.status.idle":"2021-11-13T21:02:39.732914Z","shell.execute_reply.started":"2021-11-13T21:02:39.007890Z","shell.execute_reply":"2021-11-13T21:02:39.731960Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Ok so now we have got an accuracy of around 73%. we will try to improve it. we can try to look at the importances and see what are the top sigficant features and then train the model  based on those features. ","metadata":{}},{"cell_type":"code","source":"# GET feature importance\n\nimportances =pd.DataFrame({'feature':data.iloc[:,0:11].columns,'importance': np.round(gb_model.feature_importances_,3)})\nimportances = importances.sort_values('importance', ascending = False).set_index('feature')\nimportances","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:39.734302Z","iopub.execute_input":"2021-11-13T21:02:39.734616Z","iopub.status.idle":"2021-11-13T21:02:39.758996Z","shell.execute_reply.started":"2021-11-13T21:02:39.734576Z","shell.execute_reply":"2021-11-13T21:02:39.758024Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**We see that serum_creatinine,ejection_fraction,creatinine_phosphokinase and age can be taken as features to predict heart failure. we will now train the model again to see any imporvements **","metadata":{}},{"cell_type":"code","source":"#define the target prediction and the features\nY = data['DEATH_EVENT']\nfeatures = [\"serum_creatinine\", \"ejection_fraction\", \"creatinine_phosphokinase\",\"age\"]\nX = data[features]\n# split the data set into training and testing dataset with  80:20 ratio\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train,Y_test =train_test_split(X, Y, test_size=0.2,random_state=0)\n# random state is  used  for initializing the internal random number generator, which will decide the splitting of data into train and test indices","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:39.760535Z","iopub.execute_input":"2021-11-13T21:02:39.760919Z","iopub.status.idle":"2021-11-13T21:02:39.776776Z","shell.execute_reply.started":"2021-11-13T21:02:39.760876Z","shell.execute_reply":"2021-11-13T21:02:39.776016Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# we train our model again \nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.metrics import accuracy_score\n\ngb_model = GradientBoostingClassifier(n_estimators=500, learning_rate= 0.01, random_state=0)\ngb_model.fit(X_train, Y_train)\ngb_preds = gb_model.predict(X_test)\naccuracy = accuracy_score(Y_test, gb_preds)\n\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:39.777959Z","iopub.execute_input":"2021-11-13T21:02:39.778273Z","iopub.status.idle":"2021-11-13T21:02:40.167903Z","shell.execute_reply.started":"2021-11-13T21:02:39.778218Z","shell.execute_reply":"2021-11-13T21:02:40.167091Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Training with relavant feaures the model improved by 3 percent","metadata":{}},{"cell_type":"markdown","source":"**Lets test some more models **","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nknn=KNeighborsClassifier(n_neighbors= 10,metric='minkowski',p=5)\nknn.fit(X_train,Y_train)\n\nmodel_preds = knn.predict(X_test)\naccuracy = accuracy_score(Y_test, model_preds)\n\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:40.169412Z","iopub.execute_input":"2021-11-13T21:02:40.169921Z","iopub.status.idle":"2021-11-13T21:02:40.187407Z","shell.execute_reply.started":"2021-11-13T21:02:40.169876Z","shell.execute_reply":"2021-11-13T21:02:40.186425Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nmodel_lg = LogisticRegression()\nmodel_lg.fit(X_train,Y_train)\n\nmodel_lg_predict = model_lg.predict(X_test)\naccuracy = accuracy_score(Y_test, model_lg_predict)\n\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:40.188784Z","iopub.execute_input":"2021-11-13T21:02:40.189113Z","iopub.status.idle":"2021-11-13T21:02:40.223960Z","shell.execute_reply.started":"2021-11-13T21:02:40.189073Z","shell.execute_reply":"2021-11-13T21:02:40.223205Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nmodel_lg = LogisticRegression()\nmodel_lg.fit(X_train,Y_train)\nmodel_lg_predict = model_lg.predict(X_test)\naccuracy = accuracy_score(Y_test, model_lg_predict)\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:40.227096Z","iopub.execute_input":"2021-11-13T21:02:40.227794Z","iopub.status.idle":"2021-11-13T21:02:40.263106Z","shell.execute_reply.started":"2021-11-13T21:02:40.227762Z","shell.execute_reply":"2021-11-13T21:02:40.262533Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"  # use the RandomForestClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\nforest.fit(X_train, Y_train)\nforest_predict = forest.predict(X_test)\naccuracy = accuracy_score(Y_test,forest_predict)\nprint(accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:40.264153Z","iopub.execute_input":"2021-11-13T21:02:40.264676Z","iopub.status.idle":"2021-11-13T21:02:40.300285Z","shell.execute_reply.started":"2021-11-13T21:02:40.264643Z","shell.execute_reply":"2021-11-13T21:02:40.299400Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"  # use GussianNB\nfrom sklearn.naive_bayes import GaussianNB\nguass = GaussianNB()\nguass.fit(X_train,Y_train)\nguass_predict = guass.predict(X_test)\naccuracy = accuracy_score(Y_test,guass_predict)\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:40.301942Z","iopub.execute_input":"2021-11-13T21:02:40.302245Z","iopub.status.idle":"2021-11-13T21:02:40.316557Z","shell.execute_reply.started":"2021-11-13T21:02:40.302185Z","shell.execute_reply":"2021-11-13T21:02:40.315282Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# use Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(criterion ='entropy', random_state=0)\ntree.fit(X_train, Y_train)\ntree_predict = tree.predict(X_test)\naccuracy = accuracy_score(Y_test,tree_predict)\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:40.318383Z","iopub.execute_input":"2021-11-13T21:02:40.318861Z","iopub.status.idle":"2021-11-13T21:02:40.331446Z","shell.execute_reply.started":"2021-11-13T21:02:40.318821Z","shell.execute_reply":"2021-11-13T21:02:40.330760Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":" # support vector (Linear kernel)\nfrom sklearn.svm import SVC\nsvc_lin =SVC(kernel='linear',random_state = 0)\nsvc_lin.fit(X_train, Y_train)\nsvc_predict = svc_lin.predict(X_test)\naccuracy = accuracy_score(Y_test,svc_predict)\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:02:40.332467Z","iopub.execute_input":"2021-11-13T21:02:40.332947Z","iopub.status.idle":"2021-11-13T21:03:03.306428Z","shell.execute_reply.started":"2021-11-13T21:02:40.332908Z","shell.execute_reply":"2021-11-13T21:03:03.305514Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"From the algorithms used above GradientBoostingClassifier performs the best with an accuracy of 77%","metadata":{}}]}